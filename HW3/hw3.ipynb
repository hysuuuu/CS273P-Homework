{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D3Ga2BYkhSi"
      },
      "source": [
        "# Homework 3\n",
        "#### CS 273P Machine Learning and Data Mining (Winter 2025)\n",
        "\n",
        "* Q1: Common PyTorch Operations (20 points)\n",
        "* Q2: Linear Modeling on Titanic Dataset (75 points)\n",
        "* Statement of Collaboration (5 points)\n",
        "\n",
        "## Submission guidelines\n",
        "Once you have completed the assignment in this notebook, you should export a PDF from this notebook and submit it to Gradescope. You do not need to submit anything else. Make sure your PDF contains your code, the output of each cell, and your results are not blocked or clipped significantly. Once your PDF is uploaded to Gradescope, you will be prompted to match each question with the pages in your PDF, please make sure you complete this step and do it correctly. Since this is the second assignment, and we have made our submission guidelines clear, we will not accept any submission that does not follow the guidelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKohEFLNkhSl"
      },
      "source": [
        "## Question 1: Common PyTorch Operations\n",
        "You have used PyTorch in your last assignment. In this question, let's get to know PyTorch better by performing some common operations. In practice, you will be using these operations frequently.\n",
        "\n",
        "For now, import PyTorch first. If you don't have it installed, you can install it by running `!pip install torch` in a code cell.\n",
        "\n",
        "In addition, you may find their documentation to learn more: https://pytorch.org/docs/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2JznewJkhSm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFcOJbdykhSn"
      },
      "source": [
        "### Question 1.1: Tensor Operations (5 points)\n",
        "In this question, we will look at some common code snippets you will encounter when working with PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g6EwiLdykhSn",
        "outputId": "78a20df8-7290-485f-ce23-e819b5146f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor A:  torch.Size([2, 2])\n",
            "A * B =  tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Shape of concatenated B and C: torch.Size([4, 2])\n",
            "Reshaped A:  tensor([1, 2, 3, 4])\n",
            "Random tensor:  tensor([[0.3233, 0.2995, 0.5188],\n",
            "        [0.6759, 0.5293, 0.3096],\n",
            "        [0.0694, 0.6286, 0.2765]])\n"
          ]
        }
      ],
      "source": [
        "# Create a 2D tensor\n",
        "A = torch.tensor([[1, 2], [3, 4]])\n",
        "# Create an all-ones tensor with the same shape as A\n",
        "B = torch.ones_like(A)\n",
        "# Create an all-zeros tensor with the same shape as A\n",
        "C = torch.zeros_like(A)\n",
        "\n",
        "# print(B)\n",
        "# print(C)\n",
        "##### Your code starts here #####\n",
        "\n",
        "# Print out the shape of tensor A\n",
        "print(\"Shape of tensor A: \", A.shape)\n",
        "\n",
        "# Print out the result of multiplying tensor A with tensor B\n",
        "print(\"A * B = \", A * B)\n",
        "\n",
        "# Concatenate B and C along dimension 0 and print out the shape of the result\n",
        "BC_concat = torch.cat((B, C), dim=0)\n",
        "print(\"Shape of concatenated B and C:\", BC_concat.shape)\n",
        "\n",
        "# Reshape A into a 1D tensor and print out A\n",
        "print(\"Reshaped A: \", A.view(-1))\n",
        "\n",
        "# Create a random tensor of shape (3, 3) with values from 0 to 1 and print out the tensor\n",
        "print(\"Random tensor: \", torch.rand(3, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOqTqZd-khSo"
      },
      "source": [
        "### Question 1.2: Autograd (5 points)\n",
        "Autograd is a feature offered by PyTorch that automatically computes gradients for tensors, this facilitates the updating of model parameters during training. In this question, you will work with autograd to compute gradients for a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cosoku_kkhSo",
        "outputId": "b5e400de-9928-4b6b-c94e-e3325ade0083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient:  tensor([1., 4.])\n"
          ]
        }
      ],
      "source": [
        "# Define a simple function\n",
        "def f(x):\n",
        "    return x[0] + x[1] * x[1]\n",
        "\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "# Create a 2-element 1D tensor `param` with automatic differentiation enabled\n",
        "# hint: use argument `requires_grad`\n",
        "param = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "\n",
        "# Calculate the gradient of f with respect to `param`\n",
        "# hint: use `torch.autograd.grad` function\n",
        "y = f(param)\n",
        "gradient = torch.autograd.grad(y, param)\n",
        "\n",
        "# Print out the gradient\n",
        "print(\"Gradient: \", gradient[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3--yHhMkhSp"
      },
      "source": [
        "### Question 1.3: The Neural Network Module (5 points)\n",
        "`torch.nn` provides a simple way to define neural network architectures. In this question, you will use `torch.nn` to define a simple linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tp9x_ka5khSp",
        "outputId": "5257d817-ee69-4c6a-da7a-69f750857c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:  tensor([[0.9271]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "##### Your code starts here #####\n",
        "\n",
        "# Create a Linear model using torch.nn.Linear, with input size 4 and output size 1\n",
        "model = torch.nn.Linear(in_features=4, out_features=1)\n",
        "\n",
        "# Create 1D input tensor of size 4\n",
        "input = torch.tensor([1.0, 2.0, 3.0, 4.0]).view(1, -1)\n",
        "\n",
        "# Print out the output of the model given the input tensor\n",
        "print(\"Output: \", model(input))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN-qOc24khSp"
      },
      "source": [
        "### Question 1.4: Computing Devices (5 points)\n",
        "PyTorch allows you to run your code on different devices, such as CPUs and GPUs. In this question, we will be checking for a CUDA device (NVIDIA GPU) and move data to and from it if available (don't worry if you don't have a CUDA-compatible GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG_V6frUkhSq",
        "outputId": "c388cabd-0b85-487e-d3db-16538e5bfc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor's device:  cpu\n"
          ]
        }
      ],
      "source": [
        "cuda_available = torch.cuda.is_available()  # Check if a CUDA GPU is available\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "# Define the device to be used\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "\n",
        "# Create a 4x4 tensor and move it to the device\n",
        "tensor = torch.rand(4, 4).to(device)\n",
        "\n",
        "# Print out the tensor's device\n",
        "print(\"Tensor's device: \", tensor.device)\n",
        "\n",
        "# Move it back to the CPU device\n",
        "tensor_cpu = tensor.to(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0uFxJ9ekhSq"
      },
      "source": [
        "## Question 2: Linear Modeling on Titanic Dataset\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "In this question, we ask you to build a linear model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
        "\n",
        "![titanic.png](attachment:titanic.png)\n",
        "\n",
        "Why did Rose survive and Jack didn't? Let's find out!\n",
        "\n",
        "![titanic-meme.png](attachment:titanic-meme.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiXBt-g5khSs"
      },
      "source": [
        "### Question 2.1: Data Preprocessing (25 points)\n",
        "Real world data is often messy and requires preprocessing before it can be used for modeling. This procedure is ubiquitous in real-world applications and is often referred to as \"data cleaning\" and \"feature engineering\". In this question, you will preprocess the Titanic dataset. The dataset can be found in the data folder.\n",
        "\n",
        "In this question, we will be using Pandas, a powerful tool for tabular data manipulation. If you don't have it installed, you can install it by running `!pip install pandas` in a code cell.\n",
        "\n",
        "Before we start, let's load the dataset and take a look at the first few rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "E3oy67tBkhSs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "966d09b2-b1c8-4a78-dc35-60a176ace69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n",
            "(891, 12)\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the titanic dataset\n",
        "path = \"data/titanic/train.csv\"\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# Print out the column names\n",
        "print(data.columns)\n",
        "\n",
        "# Print out the shape of the dataset\n",
        "print(data.shape)\n",
        "\n",
        "# Print out the first 5 rows of the dataset\n",
        "print(data.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqLjhsOrkhSs"
      },
      "source": [
        "Here's some information about the columns in the dataset:\n",
        "* PassengerId: Unique identifier for each passenger (index, not predictive).\n",
        "* Survived: Target variable (0 = did not survive, 1 = survived).\n",
        "* Pclass: Travel class (1 = upper, 2 = middle, 3 = lower).\n",
        "* Name: Full name, may contain titles indicating social status.\n",
        "* Sex: Gender of the passenger (male/female).\n",
        "* Age: Passenger's age in years (missing values exist).\n",
        "* SibSp: Number of siblings/spouses aboard.\n",
        "* Parch: Number of parents/children aboard.\n",
        "* Ticket: Ticket number (possible grouping or class info).\n",
        "* Fare: Ticket fare paid (proxy for socio-economic status).\n",
        "* Cabin: Cabin number (location on ship, many missing values).\n",
        "* Embarked: Port of boarding (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
        "\n",
        "Based on your intuition, do you think all of the columns are useful for predicting survival? If not, which columns can be dropped? (Answer in the markdown cell below)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qHghPuOkhSs"
      },
      "source": [
        "Not all columns are useful. These columns can be dropped:\n",
        "\n",
        "1.   PassengerId: just index, not predictive.\n",
        "\n",
        "2.   Cabin: many missing values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jaLhlEBkhSs"
      },
      "source": [
        "Building on your previous answer, drop the columns that you think are not useful for predicting survival."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4et-uS6ikhSt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f7033d58-dc40-423c-aea3-01525c057c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 10)\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                            Braund, Mr. Owen Harris   \n",
            "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
            "2         1       3                             Heikkinen, Miss. Laina   \n",
            "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
            "4         0       3                           Allen, Mr. William Henry   \n",
            "\n",
            "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
            "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
            "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
            "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
            "3  female  35.0      1      0            113803  53.1000        S  \n",
            "4    male  35.0      0      0            373450   8.0500        S  \n"
          ]
        }
      ],
      "source": [
        "##### Your code starts here #####\n",
        "\n",
        "# Drop unnecessary columns\n",
        "cleaned_data = data.drop(columns=[\"PassengerId\", \"Cabin\"])\n",
        "\n",
        "# Print out the shape of the dataset\n",
        "print(cleaned_data.shape)\n",
        "\n",
        "# Print out the first 5 rows of the dataset\n",
        "print(cleaned_data.head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW1PRULNkhSt"
      },
      "source": [
        "Some of the columns in the dataset seems to have missing values, why and how would you handle missing values in the dataset? Try to propose other ways compared to the method below. (Answer in the markdown cell below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crSdcj3fkhSt"
      },
      "source": [
        "For columns with a large number of missing values, I'll simply drop them.\n",
        "However, if the number of missing values is acceptable, such as in the \"Age\" column, I'll fill them using a mean or median value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2udQ_h4khSt"
      },
      "source": [
        "For now, we use the median value to fill the missing numerical values, and the most frequent value to fill the missing categorical values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "EbrBrlAHkhSt"
      },
      "outputs": [],
      "source": [
        "##### Your code starts here #####\n",
        "\n",
        "# Fill missing values in the \"Age\" column with the median age\n",
        "cleaned_data[\"Age\"] = cleaned_data[\"Age\"].fillna(cleaned_data[\"Age\"].median())\n",
        "\n",
        "# Fill missing values in the \"Embarked\" column with the most common port\n",
        "cleaned_data[\"Embarked\"] = cleaned_data[\"Embarked\"].fillna(cleaned_data[\"Embarked\"].mode()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io9NMNnzkhSt"
      },
      "source": [
        "Lastly, we know that computers can't handle textural data directly, so we need to convert the categorical columns into numerical columns. One common way to do this is by using one-hot encoding. It creates an one-to-one mapping between the categorical values and the numerical values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "2skJTKtAkhSt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c54654c7-4f2d-4ed9-f30f-877ef13130af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  \\\n",
            "0         0       3  22.0      1      0   7.2500      True       False   \n",
            "1         1       1  38.0      1      0  71.2833     False       False   \n",
            "2         1       3  26.0      0      0   7.9250     False       False   \n",
            "3         1       1  35.0      1      0  53.1000     False       False   \n",
            "4         0       3  35.0      0      0   8.0500      True       False   \n",
            "\n",
            "   Embarked_S  \n",
            "0        True  \n",
            "1       False  \n",
            "2        True  \n",
            "3        True  \n",
            "4        True  \n"
          ]
        }
      ],
      "source": [
        "##### Your code starts here #####\n",
        "\n",
        "# Do one-hot encoding on the categorical columns\n",
        "# hint: there's a pandas function that helps you do this\n",
        "cleaned_data = pd.get_dummies(cleaned_data, columns = [\"Sex\", \"Embarked\"], drop_first=True)\n",
        "# not using one-hot encoding on \"Name\" and \"Ticket\" because there are too many unique values\n",
        "cleaned_data = cleaned_data.drop(columns=[\"Name\", \"Ticket\"])  # dropping these two because they're object and not suitable for one-hot encoding\n",
        "\n",
        "# Print first few rows to verify\n",
        "print(cleaned_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vpQR4YZkhSt"
      },
      "source": [
        "Before we can use this data for training, we should split the data into features and target. In addition, you need to make sure that your dataset has no missing values and all columns are numerical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "SHmY3fVNkhSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3ec8828d-ce8b-48f1-839e-3054493c414a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Survived        int64\n",
            "Pclass          int64\n",
            "Age           float64\n",
            "SibSp           int64\n",
            "Parch           int64\n",
            "Fare          float64\n",
            "Sex_male         bool\n",
            "Embarked_Q       bool\n",
            "Embarked_S       bool\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "X = cleaned_data.drop(columns=[\"Survived\"]) # features\n",
        "y = cleaned_data[\"Survived\"]                # target\n",
        "\n",
        "# Check if there are any missing values in the dataset\n",
        "print(cleaned_data.isnull().sum().sum())    # this should return 0\n",
        "\n",
        "# Check if all columns are numeric\n",
        "print(cleaned_data.dtypes)                  # all columns should be numeric (or boolean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9q8-B_okhSu"
      },
      "source": [
        "Now let's do the same for our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "8k7_Dd5XkhSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f38f7e19-2a31-4291-8813-b48a447a23a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Pclass          int64\n",
            "Age           float64\n",
            "SibSp           int64\n",
            "Parch           int64\n",
            "Fare          float64\n",
            "Survived        int64\n",
            "Sex_male         bool\n",
            "Embarked_Q       bool\n",
            "Embarked_S       bool\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "path = \"data/titanic/test.csv\"\n",
        "test_data = pd.read_csv(path)\n",
        "target_path = \"data/titanic/gender_submission.csv\"\n",
        "target = pd.read_csv(target_path)\n",
        "# Merge the test data with the target data\n",
        "test_data = pd.merge(test_data, target, on=\"PassengerId\")\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "# Same preprocessing steps for the test set\n",
        "\n",
        "# Drop unnecessary columns\n",
        "test_data = test_data.drop(columns=[\"PassengerId\", \"Cabin\", \"Name\", \"Ticket\"])\n",
        "\n",
        "# Fill missing values\n",
        "test_data[\"Age\"] = test_data[\"Age\"].fillna(test_data[\"Age\"].median())\n",
        "test_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(test_data[\"Embarked\"].mode()[0])\n",
        "test_data[\"Fare\"] = test_data[\"Fare\"].fillna(test_data[\"Fare\"].median())\n",
        "# Do one-hot encoding\n",
        "test_data = pd.get_dummies(test_data, columns = [\"Sex\", \"Embarked\"], drop_first=True)\n",
        "\n",
        "# Split the test set into features and target\n",
        "# Check for missing values\n",
        "# Check for non-numeric columns\n",
        "test_X = test_data.drop(columns=[\"Survived\"]) # features\n",
        "test_y = test_data[\"Survived\"]                # target\n",
        "print(test_data.isnull().sum().sum())\n",
        "print(test_data.dtypes)\n",
        "\n",
        "# print(test_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Vs-yBBkhSu"
      },
      "source": [
        "Lastly, we convert the data into PyTorch tensors before giving it to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "tiHLwhsukhSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bc297839-354a-4cb1-af90-a6eaa9b5ddaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test X tensor shape: torch.Size([418, 8])\n",
            "Test y tensor shape: torch.Size([418, 1])\n"
          ]
        }
      ],
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = X.to_numpy(dtype=np.float32)\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "# Convert the test data as well\n",
        "test_X = test_X.to_numpy(dtype=np.float32)\n",
        "test_X_tensor = torch.tensor(test_X, dtype=torch.float32)\n",
        "test_y_tensor = torch.tensor(test_y.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "print(\"Test X tensor shape:\", test_X_tensor.shape)\n",
        "print(\"Test y tensor shape:\", test_y_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJkux_fCkhSu"
      },
      "source": [
        "### Question 2.2: Building a Linear Model (10 points)\n",
        "In this question, you will build a linear model using PyTorch to predict the survival of passengers on the Titanic. Note that the input to the model should be the features of the passengers and the output should be the predicted survival status of the passengers.\n",
        "\n",
        "Take a look at the skeleton code below, you will see that this class inherits from `torch.nn.Module` and has a method called `forward`. You will see this structure in almost all PyTorch model implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "gCid0dQ9khSv"
      },
      "outputs": [],
      "source": [
        "class LinearModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        \"\"\"\n",
        "        Model initialized with the dimension of the input features\n",
        "        \"\"\"\n",
        "        super(LinearModel, self).__init__()\n",
        "\n",
        "        ##### Your code starts here #####\n",
        "\n",
        "        # Define some basic linear layers\n",
        "        self.linear = torch.nn.Linear(input_dim, 1)\n",
        "        self.activation = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        The forward pass of the model\n",
        "        \"\"\"\n",
        "        # Implement the forward method\n",
        "        x = self.linear(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGFKcb4gkhSv"
      },
      "source": [
        "### Question 2.3: Training the Model (10 points)\n",
        "In this question, you will train the model using the training data. Training a model typically involves 4 essential components:\n",
        "\n",
        "* model\n",
        "* training data\n",
        "* loss function: target function for the model to minimize\n",
        "* optimizer: the algorithm to update the model parameters\n",
        "\n",
        "This is true for almost all machine learning systems, from simple linear regressors to large language models with billions of parameters. Thus, it is essential for you to understand what each of these components do.\n",
        "\n",
        "We have defined the model and processed the training data, now let's define a loss function and an optimizer. Since we are essentially performing binary classification, we will use the binary cross-entropy loss function. In addition, we will use the Adam optimizer to update the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "t9IyVfknkhSv"
      },
      "outputs": [],
      "source": [
        "##### Your code starts here #####\n",
        "\n",
        "# Instantiate the model\n",
        "input_dim = X_tensor.shape[1]\n",
        "model = LinearModel(input_dim)\n",
        "# Define loss function\n",
        "criterion = torch.nn.BCELoss()\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rkknNpQkhSv"
      },
      "source": [
        "Now let's implement the training loop to start training the model. Why do we need to train the model on the same data for multiple times (epochs)? (Answer in the markdown cell below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3m-7mxBkhSv"
      },
      "source": [
        "To improve the performance.\n",
        "\n",
        "Gradient descent needs multiple tries to converge to optimal solution. Additionally, the model adjusts its weights continuously during training to minimize the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "T77DwlFCkhSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9b6f5c70-e3b8-4401-efbd-bcd7efd29af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss: 20.86471\n",
            "10 loss: 2.64988\n",
            "20 loss: 1.37108\n",
            "30 loss: 0.62000\n",
            "40 loss: 0.55008\n",
            "50 loss: 0.51369\n",
            "60 loss: 0.49204\n",
            "70 loss: 0.48649\n",
            "80 loss: 0.48201\n",
            "90 loss: 0.47951\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "model.train()   # set the model to training mode\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "def train(model, criterion, optimizer, X, y, epochs):\n",
        "    # Finish implementing the training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        output = model(X)\n",
        "\n",
        "        # Compute Loss\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        # Zero gradients, backward pass, update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print out the loss every 10 epochs\n",
        "        if epoch % 10 == 0:\n",
        "          print(f\"{epoch} loss: {loss.item():.5f}\")\n",
        "##### Your code ends here #####\n",
        "\n",
        "train(model, criterion, optimizer, X_tensor, y_tensor, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzC7F1-NkhSv"
      },
      "source": [
        "### Question 2.4: Evaluation and Conclusion (30 points)\n",
        "Let's start by defining some metrics to evaluate the model. In this question, you will implement accuracy and mean squared error metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Zs7LttmqkhSw"
      },
      "outputs": [],
      "source": [
        "##### Your code starts here #####\n",
        "\n",
        "# Implement a function to calculate the accuracy of the model\n",
        "def accuracy(y_pred, y_true):\n",
        "    y_label = (y_pred >= 0.5).float() # threshhold = 0.5\n",
        "    correct = (y_label == y_true).sum().item()\n",
        "    total = y_true.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "# Implement a function to calculate the mean squared error of the model\n",
        "def mse(y_pred, y_true):\n",
        "    n = y_true.shape[0]\n",
        "    square_error = (y_pred - y_true) ** 2\n",
        "    mse = sum(square_error) / n\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haoUgSaukhSz"
      },
      "source": [
        "Next, let's evaluate the model on the test dataset using the metrics you have implemented. You should get an accuracy above 80%. If not, rerun the training process again until you get an accuracy above 80%. Explain why we get different results each time we train the model. Are there other ways to ensure we get a representative result? (Answer in the markdown cell below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo7KWvq_khSz"
      },
      "source": [
        "When starting a new training, the model gets a random initail weight. Additionally, due to the stochastic nature of the optimizer and the selection of training data batches, the model will get different optimization each time.\n",
        "As a result, we get different results every time.\n",
        "\n",
        "To ensure we get representative result, we can set specific random seed to get fixed weights and training data batches, or train for more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "Tz6yV_m2khSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7ec7a68c-bc6c-46b7-f059-43afadf76d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.65%\n",
            "Test MSE: tensor([0.0706])\n"
          ]
        }
      ],
      "source": [
        "model.eval()            # set the model to evaluation mode\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "with torch.no_grad():   # turn off gradients\n",
        "    # Implement testing and print out the accuracy and mean squared error\n",
        "    test_output = model(test_X_tensor)\n",
        "    test_accuracy = accuracy(test_output, test_y_tensor)\n",
        "    test_mse = mse(test_output, test_y_tensor)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "putOjuF_khS0"
      },
      "source": [
        "Finally, let's draw some conclusions based on the model you just trained. We will use the weights of the model to directly interpret the importance of each feature in predicting survival. Why is this possible? (Answer in the markdown cell below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdHfgpYekhS0"
      },
      "source": [
        "Since the weights in a linear model directly show how each feature affects the prediction, we can know which features matter most by looking at their coefficients. This makes linear models easy to interpret and helps us see how different factors influence survival."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "bgEW1hcLkhS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "outputId": "9f31f906-928f-4182-9d47-a0a2a9c32dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Feature  Coefficient\n",
            "6  Embarked_Q     0.132954\n",
            "7  Embarked_S     0.106140\n",
            "4        Fare     0.014540\n",
            "1         Age    -0.004586\n",
            "3       Parch    -0.111638\n",
            "0      Pclass    -0.144436\n",
            "2       SibSp    -0.292206\n",
            "5    Sex_male    -2.327243\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract coefficients from the model\n",
        "coefficients = model.linear.weight.detach().numpy().flatten()\n",
        "X = pd.DataFrame(X, columns=cleaned_data.columns[1:])\n",
        "features = X.columns\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "coef_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Coefficient\": coefficients\n",
        "}).sort_values(by=\"Coefficient\", ascending=False)\n",
        "\n",
        "\n",
        "##### Your code starts here #####\n",
        "\n",
        "# Print the coefficients\n",
        "print(coef_df)\n",
        "\n",
        "# Plot the coefficients with a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(coef_df[\"Feature\"], coef_df[\"Coefficient\"], color=\"skyblue\")\n",
        "plt.xlabel(\"Coefficient\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.gca().invert_yaxis()  # display the highest coefficient on top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SqCmUaFkhS0"
      },
      "source": [
        "Does the result align with your intuition? Why or why not? According to your results, what is the biggest contributing factor of survival? (Answer in the markdown cell below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xMNBdq0khS0"
      },
      "source": [
        "It mostly aligns with my intuition. I assume passengers with higher social status(who paid more for fares and had higher classes) would have a slightly higher survival chance. And we all know that women and children were prioritized during evacuation. What surprises me is that age has only a minor effect on survival.\n",
        "\n",
        "In my training set, the biggest factor contributing to survival was \"Embarked\"(which I don't quite understand), while being male strongly reduced the survival chance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUgbV87KkhS0"
      },
      "source": [
        "## Statement of Collaboration\n",
        "\n",
        "It is mandatory to include a Statement of Collaboration in each submission, with respect to the guidelines below.\n",
        "Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
        "\n",
        "All students are required to follow the academic honesty guidelines posted on the course website.\n",
        "For programming assignments, in particular, I encourage the students to organize (perhaps using Ed) to discuss the task descriptions, requirements, bugs in my code, and the relevant technical content before they start working on it.\n",
        "\n",
        "However, you should not discuss the specific solutions, and, as a guiding principle, you are not allowed to take anything written or drawn away from these discussions (i.e. no photographs of the blackboard, written notes, referring to Ed, etc.).\n",
        "\n",
        "Especially after you have started working on the assignment, try to restrict the discussion to Ed as much as possible, so that there is no doubt as to the extent of your collaboration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F0uXCSSkhS0"
      },
      "source": [
        "**Statement of Collaboration:** I completed this assignment independently and did not collaborate or discuss the work with anyone.\n",
        "\n",
        "reference: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}